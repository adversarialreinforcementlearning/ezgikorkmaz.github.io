<head>
  <meta name="keywords" content="adversarial, deep reinforcement learning, adversarial attacks, robust, DeepRL, DRL, adversarial policies, robust reinforcement learning, safe RL, AI safety, AI security, machine learning safety, adversarial machine learning, reinforcement learning, deep learning, explainability, interpretability, AI alignment, ML safety, ML security, machine learning safety, artificial intelligence safety, adversarial reinforcement learning, robust reinforcement learning, robust RL, adversarial RL, safe reinforcement learning, safe RL, RL security, reinforcement learning security, AI security, adversarial machine learning, human centered AI ">
</head>


I am a machine learning researcher and a PhD candidate in artificial intelligence and machine learning. I hold a Masters of Science degree in Electrical Engineering and Information Technology from Karlsruhe Institute of Technology. I wrote my MSc thesis at University of California, Berkeley. My research focus is robustness and generalization in machine learning. Currently, I am at DeepMind.



### Single Author Publications

[1] Ezgi Korkmaz. Deep Reinforcement Learning Policies Learn Shared Adversarial Features Across MDPs. AAAI Conference on Artificial Intelligence, 2022. **[Acceptance Rate: 14.58%]** <br />
[[AAAI]](https://ojs.aaai.org/index.php/AAAI/article/view/20684) [[PDF]] (https://ojs.aaai.org/index.php/AAAI/article/view/20684/20443) [[Abstract]](https://adversarialreinforcementlearning.github.io) [[Cite]](ekaaai22.html)

[2] Ezgi Korkmaz. Investigating Vulnerabilities of Deep Neural Policies. Conference on Uncertainty in Artificial Intelligence (UAI), Proceedings of Machine Learning Research (PMLR), 2021.<br />
**[Acceptance Rate: 26.38%]** <br />
[[Paper]](https://proceedings.mlr.press/v161/korkmaz21a/korkmaz21a.pdf) [[PMLR]](https://proceedings.mlr.press/v161/korkmaz21a.html) [[Abstract]](https://robustdeepreinforcementlearning.github.io/) [[News]](https://adversa.ai/blog/best-of-adversarial-ml-week-34-attacking-aerial-imagery-object-detector/) [[Cite]](ekuaibibtex.html)

[3] Ezgi Korkmaz. The Robustness of Inverse Reinforcement Learning. International Conference on Machine Learning (ICML) Artificial Intelligence for Agent Based Modelling Workshop, 2022. [[Cite]](ekicml22bibtex.html)

[4] Ezgi Korkmaz. Adversarial Attacks Against Deep Imitation and Inverse Reinforcement Learning. International Conference on Machine Learning (ICML) Complex Feedback in Online Learning Workshop, 2022. [[Cite]](ekicmlbibtex.html)

[5] Ezgi Korkmaz. Inaccuracy of State-Action Value Function For Non-Optimal Actions in Adversarially Trained Deep Neural Policies. IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPR) **[Oral Presentation]**, 2021 & International Conference on Learning Representation (ICLR) Robust and Reliable Machine Learning in the Real World Workshop, 2021.[[Paper]](https://ieeexplore.ieee.org/document/9523170) [[Slides]](https://www.youtube.com/watch?v=F3cvXrLWcoU&t=3s&ab_channel=AngelinaWang) [[Cite]](https://dblp.org/rec/conf/cvpr/Korkmaz21.html?view=bibtex)

[6] Ezgi Korkmaz. A Brief Summary on COVID-19 Pandemic and Machine Learning Approaches. International Joint Conference on Artificial Intelligence (IJCAI) Workshop on Artificial Intelligence for Social Good, 2021 & Conference on Neural Information Processing Systems (NeurIPS) Machine Learning in Public Health Workshop.<br />
**[Oral Presentation]**. [[Paper IJCAI]](ijcai21EK.pdf) [[Paper NeurIPS]](neurIPS21.pdf) [[Abstract]](https://machinelearningcovid19.github.io/) [[Cite]](ekijcaibibtex.html)

[7] Ezgi Korkmaz. Non-Robust Feature Mapping in Deep Reinforcement Learning. International Conference on Machine Learning (ICML) A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning Workshop, 2021 & Conference on Neural Information Processing Systems (NeurIPS) Metacognition in the Age of AI: Challenges and Opportunities **[Spotlight Presentation]**, 2021. [[Cite]](icmlmapbibtex.html)

[8]  Ezgi Korkmaz. Adversarial Training Blocks Generalization in Neural Policies. International Conference on Learning Representation (ICLR) Robust and Reliable Machine Learning in the Real World Workshop, 2021 & Conference on Neural Information Processing Systems (NeurIPS) Workshop on Distribution Shifts: Connecting Methods and Applications, 2021 & Conference on Neural Information Processing Systems (NeurIPS) Safe and Robust Control of Uncertain Systems Workshop, 2021 & Conference on Neural Information Processing Systems (NeurIPS) I Can't Believe It's Not Better Workshop, 2021. [[Paper ICLR]](iclr.pdf) [[Paper NeurIPS]](https://openreview.net/pdf?id=fXGimmbtD9c) [[Cite]](eknaturalbibtex.html)

[9] Ezgi Korkmaz. Nesterov Momentum Adversarial Perturbations in the Deep Reinforcement Learning Domain. International Conference on Machine Learning (ICML) Inductive Biases, Invariances and Generalization in Reinforcement Learning Workshop, 2020. [[Cite]](ekicmlnesterovbibtex.html)

[10] Ezgi Korkmaz. Adversarially Trained Neural Policies in Fourier Domain. International Conference on Learning Representation (ICLR) Robust and Reliable Machine Learning in the Real World Workshop,2021 & International Conference on Machine Learning (ICML) A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning Workshop, 2021. [[Cite]](ekfourierbibtex.html)

